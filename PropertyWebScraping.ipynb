{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install requests beautifulsoup4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_VwO8NAY9ui",
        "outputId": "df55374d-2be6-4138-9a48-ea91450fb586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import json\n",
        "import time\n",
        "\n",
        "def scrape_real_estate_data(location):\n",
        "    base_url = f'https://www.zillow.com/homes/{location}_rb/'\n",
        "\n",
        "    headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
        "    'Accept-Language': 'en-US,en;q=0.9',\n",
        "    'Accept-Encoding': 'gzip, deflate, br',\n",
        "    'Referer': 'https://www.google.com/',\n",
        "    'Connection': 'keep-alive',\n",
        "}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(base_url, headers=headers)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            listings = []\n",
        "\n",
        "            for item in soup.find_all('article', class_='list-card'):\n",
        "                title = item.find('a', class_='list-card-link').text.strip()\n",
        "                price = item.find('div', class_='list-card-price').text.strip()\n",
        "                url = 'https://www.zillow.com' + item.find('a', class_='list-card-link')['href']\n",
        "\n",
        "                listings.append({\n",
        "                    'title': title,\n",
        "                    'price': price,\n",
        "                    'url': url\n",
        "                })\n",
        "\n",
        "                # Save data to CSV\n",
        "                with open('real_estate_data.csv', 'w', newline='', encoding='utf-8') as csv_file:\n",
        "                    csv_writer = csv.DictWriter(csv_file, fieldnames=['title', 'price', 'url'])\n",
        "                    csv_writer.writeheader()\n",
        "                    csv_writer.writerows(listings)\n",
        "\n",
        "                # Save data to JSON\n",
        "                with open('real_estate_data.json', 'w', encoding='utf-8') as json_file:\n",
        "                    json.dump(listings, json_file, ensure_ascii=False, indent=2)\n",
        "\n",
        "            print(\"Scraping completed successfully.\")\n",
        "        else:\n",
        "            print(f\"Error: {response.status_code}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "    finally:\n",
        "        # Analytics summary\n",
        "        total_listings = len(listings) if 'listings' in locals() else 0\n",
        "        print(f\"\\n--- Analytics Summary ---\")\n",
        "        print(f\"Total Listings Scraped: {total_listings}\")\n",
        "        if 'e' in locals():\n",
        "            print(f\"Errors Encountered: {e}\")\n",
        "        print(\"------------------------\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    location = \"san-francisco\"  # Change this to your desired city or zip code\n",
        "    scrape_real_estate_data(location)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9C4_AEqOaU76",
        "outputId": "75c61ad4-6a5f-4c48-8cc6-15d929bf5e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping completed successfully.\n",
            "\n",
            "--- Analytics Summary ---\n",
            "Total Listings Scraped: 0\n",
            "------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}